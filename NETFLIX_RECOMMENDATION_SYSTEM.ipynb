{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakshiharde/Netflix_Movie_And_Tvshows_RecommendationSystem/blob/main/NETFLIX_RECOMMENDATION_SYSTEM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Netflix Movies and TV shows Recommendation System\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix=pd.read_csv('/content/drive/MyDrive/content/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')"
      ],
      "metadata": {
        "id": "EnCHOuUQPXcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "netflix.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix.tail()"
      ],
      "metadata": {
        "id": "vrB67NSQP93Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "netflix.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "netflix.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix.describe()"
      ],
      "metadata": {
        "id": "ZJD1btfYQPo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "netflix.duplicated().sum()\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "netflix.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the dataset , the director colummn has 2389 missing values , cast has 718 missing values and country has 507 missing values , date_added has 10 values and rating has 7 value missing"
      ],
      "metadata": {
        "id": "jTFFNvKAQoKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "netflix.isnull().sum().plot(kind='bar')\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SynaXoj_tLIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "netflix.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "netflix.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "netflix.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "netflix.isnull().sum()\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling Null Values\n",
        "netflix['cast'].fillna(value='No cast',inplace=True)\n",
        "netflix['country'].fillna(value=netflix['country'].mode()[0],inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "fYJ1mj75Rxpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix.dropna(subset=['date_added','rating'],inplace=True)\n"
      ],
      "metadata": {
        "id": "m6hEewivTz9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the null values in director.\n",
        "netflix['director']=netflix['director'].fillna('')\n"
      ],
      "metadata": {
        "id": "MLg6s29rT3pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix.isnull().sum()"
      ],
      "metadata": {
        "id": "yR_sb2VUR3zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. How many TV shows and movies are on Netflix?"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='type',data=netflix,hue='type')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix has 5372 movies and 2398 TV shows, there are more number movies on Netflix than TV shows."
      ],
      "metadata": {
        "id": "468CCCxDWTkD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is the most common rating for movies and TV shows on Netflix?"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "rating_counts = netflix['rating'].value_counts()\n",
        "plt.pie(rating_counts, labels=rating_counts.index, autopct='%1.1f%%')\n",
        "plt.title('Distribution of Ratings')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='rating', data=netflix)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6nX6aqIYYN59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By analyzing these charts, you can gain insights into the content available on Netflix and the preferences of its audience. For example:\n",
        "\n",
        "\n",
        "*   Content Strategy: If you find that certain rating categories are underrepresented, Netflix could consider adding more content with those ratings to cater to a wider audience.\n",
        "*   Parental Controls: The distribution of ratings can inform the development of parental control features, ensuring that children are only exposed to age-appropriate content.\n",
        "\n",
        "*   Marketing and Recommendations: Understanding the popularity of different rating categories can help Netflix tailor its marketing campaigns and recommendation algorithms to better target specific audience segments.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How does the distribution of release years for movies compare to that of TV shows?"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# For movies\n",
        "movie_year_counts = netflix[netflix['type'] == 'Movie']['release_year'].value_counts().reset_index()\n",
        "movie_year_counts.columns = ['release_year', 'count']\n",
        "fig_movie = px.bar(movie_year_counts.head(10), x='release_year', y='count',\n",
        "                     title='Top 10 Most Common Release Years for Movies',\n",
        "                     labels={'release_year': 'Release Year', 'count': 'Count'})\n",
        "fig_movie.show()\n",
        "\n",
        "# For TV shows\n",
        "tvshow_year_counts = netflix[netflix['type'] == 'TV Show']['release_year'].value_counts().reset_index()\n",
        "tvshow_year_counts.columns = ['release_year', 'count']\n",
        "fig_tvshow = px.bar(tvshow_year_counts.head(10), x='release_year', y='count',\n",
        "                      title='Top 10 Most Common Release Years for TV Shows',\n",
        "                      labels={'release_year': 'Release Year', 'count': 'Count'})\n",
        "fig_tvshow.show()"
      ],
      "metadata": {
        "id": "O_Y03ONyyCVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Combine movie and TV show data\n",
        "movie_year_counts = netflix[netflix['type'] == 'Movie']['release_year'].value_counts().reset_index()\n",
        "movie_year_counts.columns = ['release_year', 'count']\n",
        "movie_year_counts['type'] = 'Movie'\n",
        "\n",
        "tvshow_year_counts = netflix[netflix['type'] == 'TV Show']['release_year'].value_counts().reset_index()\n",
        "tvshow_year_counts.columns = ['release_year', 'count']\n",
        "tvshow_year_counts['type'] = 'TV Show'\n",
        "\n",
        "combined_counts = pd.concat([movie_year_counts, tvshow_year_counts])\n",
        "\n",
        "# Create line plot with different colors\n",
        "fig = px.line(combined_counts, x='release_year', y='count', color='type',\n",
        "              title='Most Common Release Years for Movies and TV Shows',\n",
        "              labels={'release_year': 'Release Year', 'count': 'Count', 'type': 'Type'})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "OesIsP5I0zPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pyFTJs7GykEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Which month sees the highest number of content additions? What factors might contribute to this peak?"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netflix"
      ],
      "metadata": {
        "id": "eMlvL00q1Se8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "netflix['month'] = pd.DatetimeIndex(netflix['date_added']).month\n",
        "netflix.head()"
      ],
      "metadata": {
        "id": "XTaDVknY3lrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the Countplot\n",
        "plt.figure(figsize=(10,10))\n",
        "ax=sns.countplot(x='month',data=netflix,palette='viridis')\n",
        "plt.xlabel(\"Month\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Count of Movies and TV Shows Added to Netflix by Month\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5Mjut8O93w9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, ax = plt.subplots(figsize=(15,6))\n",
        "\n",
        "sns.countplot(x='month', hue='type',lw=5, data=netflix, ax=ax)"
      ],
      "metadata": {
        "id": "cwByxD9BsTGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Peak Release Months: This could indicate strategic release periods targeted at specific viewer behaviors or industry trends. For example, if you see a spike in releases during the holiday season (November/December), it could suggest Netflix capitalizes on increased viewership during those times.\n",
        "*   Content Slumps:  any months with significantly lower content additions. These periods might be due to production cycles, industry events, or strategic decisions to focus releases elsewhere.\n",
        "\n"
      ],
      "metadata": {
        "id": "53XOJ_Ex2PtX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.Who are the most frequently appearing actors on Netflix?"
      ],
      "metadata": {
        "id": "9e7jsNml5HqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the 'cast' column and flatten the list\n",
        "all_actors = netflix['cast'].str.split(', ').explode()\n",
        "\n",
        "all_actors_dropped=all_actors.dropna()\n",
        "\n",
        "# Count the occurrences of each actor\n",
        "actor_counts = all_actors.value_counts()\n",
        "\n",
        "# Display the top 10 actors\n",
        "print(actor_counts.head(10))"
      ],
      "metadata": {
        "id": "ayzW1S8w5G6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "actor_counts.head(10).plot(kind='bar')\n",
        "plt.title('Top 10 Actors on Netflix')\n",
        "plt.xlabel('Actor')\n",
        "plt.ylabel('Number of Appearances')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s3Po_cmtqEOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Generate a word cloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(actor_counts)\n",
        "\n",
        "# Display the word cloud\n",
        "plt.figure(figsize=(10, 8), facecolor=None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z24pZqjLtGEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Does the dominance of US-produced content reflect global viewer preferences, or is it a result of Netflix's origins and initial focus?"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split, explode, and count country occurrences\n",
        "country_counts = netflix['country'].str.split(', ').explode().value_counts()\n",
        "\n",
        "# Display the top 10 countries\n",
        "print(country_counts.head(10))\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "country_counts.head(10).sort_values(ascending=True).plot(kind='barh', color=plt.cm.Paired(np.arange(10)))\n",
        "plt.title('Top 10 Countries Producing Content on Netflix')\n",
        "plt.ylabel('Country')\n",
        "plt.xlabel('Number of Movies and TV Shows')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gZfnIAzkuUOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99', '#c2c2f0','#ffb3e6', '#c2d6d6', '#e6b3b3', '#b3e6cc', '#ffff99']\n",
        "# Create a pie chart\n",
        "plt.figure(figsize=(8, 8))\n",
        "country_counts.head(10).plot(kind='pie', autopct='%1.1f%%', startangle=90, colors=colors)\n",
        "plt.title('Top 10 Countries Producing Content on Netflix')\n",
        "plt.ylabel('')  # Hide the default y-axis label\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Ye3fBU1wQBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The United States dominates Netflix content production with a staggering 2555 titles, followed by India with 923 and the United Kingdom with 397. Other countries contribute significantly less, indicating a concentrated production landscape led by these major players."
      ],
      "metadata": {
        "id": "TJ22ThXtu9Gb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the distribution of Movie Durations\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.distplot(netflix['duration'].str.extract('(\\d+)'),kde=False, color=['red'])\n",
        "plt.title('Distplot with Normal distribution for Movies',fontweight=\"bold\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv_shows=netflix[netflix['type']=='TV Show']\n",
        "movies=netflix[netflix['type']=='Movie']"
      ],
      "metadata": {
        "id": "yJR4RJNMz16W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the distribution of TV SHOWS\n",
        "plt.figure(figsize=(30,6))\n",
        "plt.title(\"Distribution of TV Shows duration\",fontweight='bold')\n",
        "sns.countplot(x=tv_shows['duration'],data=tv_shows,order = tv_shows['duration'].value_counts().index,palette='viridis')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JWKlcHA2zmcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How can Netflix leverage this genre data to improve its recommendation algorithms and personalize user experiences?"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split, explode, and count genre occurrences\n",
        "genre_counts = netflix['listed_in'].str.split(', ').explode().value_counts()\n",
        "\n",
        "# Display the top 10 genres\n",
        "print(genre_counts.head(10))"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "genre_counts.head(10).plot(kind='bar', color='skyblue')\n",
        "plt.title('Top 10 Genres on Netflix')\n",
        "plt.xlabel('Genre')\n",
        "plt.ylabel('Number of Movies and TV Shows')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for readability\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uT8ZZFRHxzjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "International Movies, Dramas, and Comedies are the most prevalent genres on Netflix, suggesting a strong viewer preference for these categories.\n",
        "The popularity of international movies and TV shows suggests a strong focus on acquiring and producing content from diverse regions, catering to a global audience."
      ],
      "metadata": {
        "id": "qFSONyAcy2JM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What are the most common words used in Netflix show titles?"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Combine all titles into a single string\n",
        "all_titles = ' '.join(netflix['title'].astype(str))\n",
        "\n",
        "# Split the string into individual words\n",
        "words = all_titles.lower().split()\n",
        "\n",
        "# Count the frequency of each word\n",
        "word_counts = Counter(words)\n",
        "\n",
        "# Display the most common words\n",
        "print(word_counts.most_common(10))"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "Uy9TSVn4fWQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "ps=PorterStemmer()\n",
        "import string"
      ],
      "metadata": {
        "id": "W__JuKzXfmuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment_words = ''\n",
        "\n",
        "# Remove The Stopwords\n",
        "stopwords = set(stopwords.words('english'))\n",
        "\n",
        "# Iterate Through The Column\n",
        "for val in netflix.title:\n",
        "\n",
        "    # Typecaste Each Val to String\n",
        "    val = str(val)\n",
        "\n",
        "    # Split The Value\n",
        "    tokens = val.split()\n",
        "\n",
        "    # Converts Each Token into lowercase\n",
        "    for i in range(len(tokens)):\n",
        "        tokens[i] = tokens[i].lower()\n",
        "\n",
        "    comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "# Set Parameters\n",
        "wordcloud = WordCloud(width = 1000, height = 500,\n",
        "                background_color ='white',\n",
        "                stopwords = stopwords,\n",
        "                min_font_size = 10,\n",
        "                max_words = 1000,\n",
        "                colormap = 'gist_heat_r').generate(comment_words)\n",
        "\n",
        "plt.figure(figsize = (6,6), facecolor = None)\n",
        "plt.title('Most Used Words In Shows Title', fontsize = 15, pad=20)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        "\n",
        "# Display Chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JkCVRpwoixaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most common words in Netflix titles heavily emphasize personal relationships and everyday experiences, suggesting a focus on relatable and emotionally resonant stories.\n",
        "Action and thriller titles frequently use words like 'devill', 'dead', and 'war', indicating a focus on high-stakes plots and suspense."
      ],
      "metadata": {
        "id": "RIeLYIdsiuFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# who are the top 10 movies and tv shows actors on netflix?"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cast = netflix['cast'].str.split(', ', expand=True).stack()\n",
        "\n",
        "# top actors name who play highest role in movie/show.\n",
        "cast.value_counts()\n"
      ],
      "metadata": {
        "id": "DZ_RrzL-l7ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cast =cast[cast != 'No cast']\n",
        "cast.head()"
      ],
      "metadata": {
        "id": "s5huvs0klbnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "fig,ax = plt.subplots(1,2, figsize=(14,5))\n",
        "\n",
        "# seperating TV shows actor from cast column\n",
        "top_TVshows_actor = netflix[netflix['type']=='TV Show']['cast'].str.split(', ', expand=True).stack()\n",
        "top_TVshows_actor =top_TVshows_actor[top_TVshows_actor != 'No cast']\n",
        "# plotting actor who appeared in highest number of TV Show\n",
        "a = top_TVshows_actor.value_counts().head(10).plot(kind='barh', ax=ax[0],color='purple')\n",
        "a.set_title('Top 10 TV shows actors', size=15)\n",
        "\n",
        "# seperating movie actor from cast column\n",
        "top_movie_actor = netflix[netflix['type']=='Movie']['cast'].str.split(', ', expand=True).stack()\n",
        "top_movie_actor =top_movie_actor[top_movie_actor != 'No cast']\n",
        "# plotting actor who appeared in highest number of Movie\n",
        "b = top_movie_actor.value_counts().head(10).plot(kind='barh', ax=ax[1],color='blue')\n",
        "b.set_title('Top 10 Movie actors', size=15)\n",
        "\n",
        "plt.tight_layout(pad=1.2, rect=[0, 0, 0.95, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bHVACs-TmOi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the TV shows category, the actor with the highest appearance is Takahiro Sakurai. In the movies category, the actor with the highest appearance is Anupam Kher."
      ],
      "metadata": {
        "id": "9mGMl-JMnIpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directors_list = netflix.director.value_counts().reset_index().head(15)[1:]\n",
        "directors_list.rename(columns={'index':'count', 'director':'directors name'}, inplace=True)\n",
        "\n",
        "# Create a bar chart using Plotly\n",
        "fig = px.bar(directors_list, x='directors name', y='count', text_auto=True)\n",
        "\n",
        "# Generate a list of 25 unique color codes using seaborn\n",
        "color_palette = sns.color_palette('bright', n_colors=15).as_hex()\n",
        "fig.update_traces(marker_color=color_palette)\n",
        "\n",
        "# Add a title and adjust the layout\n",
        "fig.update_layout(\n",
        "    title={\n",
        "        'text': 'Top 25 directors with highest number of Movies and Tv Shows.',\n",
        "        'y': 0.95,\n",
        "        'x': 0.5,\n",
        "        'xanchor': 'center',\n",
        "        'yanchor': 'top'},\n",
        "    autosize=False,\n",
        "    width=1200,\n",
        "    height=500\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = {\n",
        "    'TV-PG': 'Older Kids',\n",
        "    'TV-MA': 'Adults',\n",
        "    'TV-Y7-FV': 'Older Kids',\n",
        "    'TV-Y7': 'Older Kids',\n",
        "    'TV-14': 'Teens',\n",
        "    'R': 'Adults',\n",
        "    'TV-Y': 'Kids',\n",
        "    'NR': 'Adults',\n",
        "    'PG-13': 'Teens',\n",
        "    'TV-G': 'Kids',\n",
        "    'PG': 'Older Kids',\n",
        "    'G': 'Kids',\n",
        "    'UR': 'Adults',\n",
        "    'NC-17': 'Adults'\n",
        "}\n",
        "netflix['target_ages'] = netflix['rating'].replace(ratings)"
      ],
      "metadata": {
        "id": "UrnK--UByu7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix['count'] = 1\n",
        "data = netflix.groupby('country')[['count']].sum().sort_values(by='count',ascending=False).reset_index()[:10]\n",
        "data = data['country']\n",
        "\n",
        "netflix_heatmap = netflix.loc[netflix['country'].isin(data)]\n",
        "netflix_heatmap = pd.crosstab(netflix_heatmap['country'],netflix_heatmap['target_ages'],normalize = \"index\").T\n",
        "netflix_heatmap"
      ],
      "metadata": {
        "id": "bZ7W2c1RxwIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the heatmap\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
        "\n",
        "country_order2 = ['United States', 'India', 'United Kingdom', 'Canada', 'Japan', 'France', 'South Korea', 'Spain']\n",
        "\n",
        "age_order = ['Adults', 'Teens', 'Older Kids', 'Kids']\n",
        "\n",
        "sns.heatmap(netflix_heatmap.loc[age_order,country_order2],cmap=\"PRGn\",square=True, linewidth=2.5,cbar=False,\n",
        "            annot=True,fmt='1.0%',vmax=.6,vmin=0.05,ax=ax,annot_kws={\"fontsize\":12})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "usyTjaoDxk1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix['count'] = 1\n",
        "data1 = netflix.groupby('listed_in')[[ 'count']].sum().sort_values(by='count', ascending=False).reset_index()[:10]\n",
        "data1 = data1['listed_in']\n"
      ],
      "metadata": {
        "id": "KIQshjKdkx79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_heatmap1 = netflix.loc[netflix['listed_in'].isin(data1)]\n",
        "df_heatmap1 = pd.crosstab(df_heatmap1['listed_in'],df_heatmap1['target_ages'],normalize = \"index\").T\n",
        "df_heatmap1"
      ],
      "metadata": {
        "id": "b-JMZMudlU_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
        "\n",
        "top=['Documentaries', 'Stand-Up Comedy', 'Dramas, International Movies',\n",
        "       'Comedies, Dramas, International Movies',\n",
        "       'Dramas, Independent Movies, International Movies', \"Kids' TV\",\n",
        "       'Children & Family Movies', 'Documentaries, International Movies',\n",
        "       'Children & Family Movies, Comedies',\n",
        "       'Comedies, International Movies']\n",
        "age_order = ['Adults', 'Teens', 'Older Kids', 'Kids']\n",
        "\n",
        "sns.heatmap(data=df_heatmap1.loc[age_order, top],\n",
        "            cmap='YlGnBu',\n",
        "            square=True,\n",
        "            linewidth=2.5,\n",
        "            cbar=False,\n",
        "            annot=True,\n",
        "            fmt='1.0%',\n",
        "            vmax=.6,\n",
        "            vmin=0.05,\n",
        "            ax=ax,\n",
        "            annot_kws={\"fontsize\": 12})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ygyU3rBKlmWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These visualisations show the content's country of origin, which include both Movies and TVs shows. Top of the list of nations were the US and India. A few countries, including Australia, Taiwan, and Brazil, produce little Netflix content.\n",
        "\n",
        "From the heatmap,the US and UK are very similar to the Netflix target age group, although they differ greatly from such as India or Japan."
      ],
      "metadata": {
        "id": "s65UbEX0zJky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Select relevant numeric columns for the pair plot\n",
        "columns_for_pairplot = ['release_year', 'duration']  # Add or remove columns as needed\n",
        "\n",
        "# Create the pair plot\n",
        "sns.pairplot(netflix[columns_for_pairplot], diag_kind='kde')\n",
        "plt.suptitle(\"Pair Plot of Selected Netflix Features\", y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making copy of df_clean_frame\n",
        "netflix_hypothesis=netflix.copy()\n",
        "#head of df_hypothesis\n",
        "netflix_hypothesis.head()"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filtering movie from Type_of_show column\n",
        "netflix_hypothesis = netflix_hypothesis[netflix_hypothesis[\"type\"] == \"Movie\"]"
      ],
      "metadata": {
        "id": "TUEMjFDPl-_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#with respect to each ratings assigning it into group of categories\n",
        "ratings_ages = {\n",
        "    'TV-PG': 'Older Kids',\n",
        "    'TV-MA': 'Adults',\n",
        "    'TV-Y7-FV': 'Older Kids',\n",
        "    'TV-Y7': 'Older Kids',\n",
        "    'TV-14': 'Teens',\n",
        "    'R': 'Adults',\n",
        "    'TV-Y': 'Kids',\n",
        "    'NR': 'Adults',\n",
        "    'PG-13': 'Teens',\n",
        "    'TV-G': 'Kids',\n",
        "    'PG': 'Older Kids',\n",
        "    'G': 'Kids',\n",
        "    'UR': 'Adults',\n",
        "    'NC-17': 'Adults'\n",
        "}\n",
        "\n",
        "netflix_hypothesis['target_ages'] = netflix_hypothesis['rating'].replace(ratings_ages)\n",
        "#let's see unique target ages\n",
        "netflix_hypothesis['target_ages'].unique()\n",
        ""
      ],
      "metadata": {
        "id": "9YoItTLFmFHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_hypothesis['target_ages'] = pd.Categorical(netflix_hypothesis['target_ages'], categories=['Kids', 'Older Kids', 'Teens', 'Adults'])\n",
        "\n",
        "netflix_hypothesis['duration'] = netflix_hypothesis['duration'].astype(str)  # Convert to string type\n",
        "netflix_hypothesis['duration'] = netflix_hypothesis['duration'].str.extract('(\\d+)')\n",
        "netflix_hypothesis['duration'] = pd.to_numeric(netflix_hypothesis['duration'])\n",
        "\n",
        "netflix_hypothesis.head(3)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "fntt5zPumOJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#group_by duration and target_ages\n",
        "group_by_= netflix_hypothesis[['duration','target_ages']].groupby(by='target_ages')\n",
        "#mean of group_by variable\n",
        "group=group_by_.mean().reset_index()\n",
        "group\n",
        ""
      ],
      "metadata": {
        "id": "CiRQYb3FmWpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#group_by duration and target_ages\n",
        "group_by_= netflix_hypothesis[['duration','target_ages']].groupby(by='target_ages')\n",
        "#mean of group_by variable\n",
        "group=group_by_.mean().reset_index()\n",
        "group\n",
        "\n",
        "#In A and B variable grouping values\n",
        "A= group_by_.get_group('Kids')\n",
        "B= group_by_.get_group('Older Kids')\n",
        "\n",
        "# Convert 'duration' to numeric before calculating mean and std\n",
        "A['duration'] = pd.to_numeric(A['duration'])\n",
        "B['duration'] = pd.to_numeric(B['duration'])\n",
        "\n",
        "#mean and std. calutation for kids and older kids variables\n",
        "M1 = A['duration'].mean() # Calculate mean of the 'duration' column\n",
        "S1 = A['duration'].std()\n",
        "\n",
        "M2= B['duration'].mean()\n",
        "S2 = B['duration'].std()\n",
        "\n",
        "print('Mean for movies rated for Kids {} \\n Mean for  movies rated for older kids {}'.format(M1,M2))\n",
        "print('Std for  movies rated for Older Kids {} \\n Std for  movies rated for kids {}'.format(S2,S1))"
      ],
      "metadata": {
        "id": "IlJ40ESom5PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import stats\n",
        "from scipy import stats\n",
        "#length of groups and DOF\n",
        "n1 = len(A)\n",
        "n2= len(B)\n",
        "print(n1,n2)\n",
        "\n",
        "dof = n1+n2-2\n",
        "print('dof',dof)\n",
        "\n",
        "sp_2 = ((n2-1)*S1**2  + (n1-1)*S2**2) / dof\n",
        "print('SP_2 =',sp_2)\n",
        "\n",
        "sp = np.sqrt(sp_2)\n",
        "print('SP',sp)\n",
        "\n",
        "#tvalue\n",
        "t_val = (M1-M2)/(sp * np.sqrt(1/n1 + 1/n2))\n",
        "print('tvalue',t_val) # Remove [0] to print the scalar value directly"
      ],
      "metadata": {
        "id": "JvBQDG-znp1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#t-distribution\n",
        "stats.t.ppf(0.025,dof)"
      ],
      "metadata": {
        "id": "wTitglGVnpxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#t-distribution\n",
        "stats.t.ppf(0.975,dof)"
      ],
      "metadata": {
        "id": "W5usaw5zn6T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "t-value is not in the range, the null hypothesis is rejected."
      ],
      "metadata": {
        "id": "XWd4slxIoa7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a result, movies rated for kids and older kids are not at least two hours long."
      ],
      "metadata": {
        "id": "IZbkuvq7odB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H1:The duration which is more than 90 mins are movies"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HO:The duration which is more than 90 mins are NOT movies"
      ],
      "metadata": {
        "id": "LtA20kfjotJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making copy of df_clean_frame\n",
        "netflix_hypothesis=netflix.copy()\n",
        "#head of df_hypothesis\n",
        "netflix_hypothesis.head()"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_hypothesis['duration']= netflix_hypothesis['duration'].str.extract('(\\d+)')\n",
        "netflix_hypothesis['duration'] = pd.to_numeric(netflix_hypothesis['duration'])"
      ],
      "metadata": {
        "id": "hHttf3Rpo-DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_hypothesis['type'] = pd.Categorical(netflix_hypothesis['type'], categories=['Movie','TV Show'])\n",
        "#from duration feature extractin string part and after extracting Changing the object type to numeric\n",
        "#df_hypothesis['duration']= df_hypothesis['duration'].str.extract('(\\d+)')\n",
        "#df_hypothesis['duration'] = pd.to_numeric(df_hypothesis['duration'])\n",
        "#head of df_\n",
        "netflix_hypothesis.head(3)\n",
        ""
      ],
      "metadata": {
        "id": "xs-k1cHvpEIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix_hypothesis['type'] = pd.Categorical(netflix_hypothesis['type'], categories=['Movie','TV Show'])"
      ],
      "metadata": {
        "id": "XPlF3NS8pKFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "#group_by duration and TYPE\n",
        "group_by_= netflix_hypothesis[['duration','type']].groupby(by='type')\n",
        "#mean of group_by variable\n",
        "group1=group_by_.mean().reset_index()\n",
        "group1"
      ],
      "metadata": {
        "id": "UlwxAuWMpPG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In A and B variable grouping values\n",
        "A= group_by_.get_group('Movie')['duration'] # Select only the 'duration' column\n",
        "B= group_by_.get_group('TV Show')['duration'] # Select only the 'duration' column\n",
        "\n",
        "#mean and std\n",
        "M1 = A.mean()\n",
        "S1 = A.std()\n",
        "\n",
        "M2= B.mean()\n",
        "S2 = B.std()\n",
        "\n",
        "print('Mean of Movie durations: {}'.format(M1)) # Format the output for clarity\n",
        "print('Mean of TV Show durations: {}'.format(M2))\n",
        "print('Std of Movie durations: {}'.format(S1))\n",
        "print('Std of TV Show durations: {}'.format(S2))"
      ],
      "metadata": {
        "id": "-8-mpXblpvla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import stats\n",
        "from scipy import stats\n",
        "#length of groups and DOF\n",
        "n1 = len(A)\n",
        "n2= len(B)\n",
        "print(n1,n2)\n",
        "\n",
        "dof = n1+n2-2\n",
        "print('dof',dof)\n",
        "\n",
        "sp_2 = ((n2-1)*S1**2  + (n1-1)*S2**2) / dof\n",
        "print('SP_2 =',sp_2)\n",
        "\n",
        "sp = np.sqrt(sp_2)\n",
        "print('SP',sp)\n",
        "\n",
        "#tvalue\n",
        "t_val = (M1-M2)/(sp * np.sqrt(1/n1 + 1/n2))\n",
        "print('tvalue',t_val) # Remove [0] to print the scalar value directly"
      ],
      "metadata": {
        "id": "bfmGRi-JqCYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "t-distribution\n",
        "     "
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#t-distribution\n",
        "stats.t.ppf(0.025,dof)"
      ],
      "metadata": {
        "id": "_BmcMMIdqdpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#t-distribution\n",
        "stats.t.ppf(0.975,dof)"
      ],
      "metadata": {
        "id": "YKZOT8isqmdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining all the clustering attributes into a single column\n",
        "netflix['clustering'] = (netflix['director'] + ' ' + netflix['cast'] +' ' +\n",
        "                                 netflix['country'] +' ' + netflix['listed_in'] +\n",
        "                                 ' ' + netflix['description'])"
      ],
      "metadata": {
        "id": "cSE5IG0iq6HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix['clustering'][25]"
      ],
      "metadata": {
        "id": "sUeDb9Ofq-CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method 1: IQR (Interquartile Range)\n",
        "Q1 = netflix_hypothesis['clustering'].quantile(0.25)\n",
        "Q3 = netflix_hypothesis['clustering'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "netflix_hypothesis_no_outliers_iqr = netflix_hypothesis[(netflix_hypothesis['relevant_column'] >= lower_bound) & (netflix_hypothesis['relevant_column'] <= upper_bound)]\n",
        "\n",
        "# Method 2: Z-Score\n",
        "from scipy import stats\n",
        "z_scores = np.abs(stats.zscore(netflix_hypothesis['relevant_column']))\n",
        "netflix_hypothesis_no_outliers_zscore = netflix_hypothesis[(z_scores < 3)]\n",
        "\n",
        "# Method 3: Winsorization (Cap extreme values)\n",
        "from scipy.stats.mstats import winsorize\n",
        "netflix_hypothesis['relevant_column_winsorized'] = winsorize(netflix_hypothesis['relevant_column'], limits=[0.05, 0.05])\n",
        "\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "# Lower Casing\n",
        "# Remove Punctuations\n",
        "# Remove URLs & Remove words and digits contain digits\n",
        "# Remove Stopwords\n",
        "# Remove White spaces\n",
        "# Rephrase Text\n",
        "# Tokenization\n",
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('all',quiet=True)\n",
        "from PIL import Image\n",
        "\n",
        "def transform_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Tokenize text into words\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # Remove non-alphanumeric characters\n",
        "    words = [word for word in words if word.isalnum()]\n",
        "\n",
        "    # Remove stopwords and punctuation\n",
        "    stopwords_set = set(stopwords.words('english'))\n",
        "    punctuation_set = set(string.punctuation)\n",
        "    words = [word for word in words if word not in stopwords_set and word not in punctuation_set]\n",
        "\n",
        "    # Lemmatize words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "    # Join words into a string and return\n",
        "    return ' '.join(lemmatized_words)"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix['Clean_Text'] = netflix['clustering'].apply(transform_text)\n",
        ""
      ],
      "metadata": {
        "id": "AtdXZfMNvdNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflix[\"Clean_Text\"][50]"
      ],
      "metadata": {
        "id": "wIr1jP3Bv4KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF combines two metrics: Term frequency (TF) and inverse document frequency (IDF).\n",
        "\n",
        "Term Frequency (TF): This metric measures the frequency of a term in a document. It assumes that the more often a term appears in a document, the more relevant it is to that document. It is calculated using the formula:\n",
        "\n",
        "TF(t, d) = (Number of times term t appears in document d) / (Total number of terms in document d)\n",
        "\n",
        "Inverse Document Frequency (IDF): This metric measures the importance of a term across a collection of documents. It gives higher weight to terms that appear less frequently in the entire collection. It is calculated using the formula:\n",
        "\n",
        "IDF(t) = log_e(Total number of documents / Number of documents containing term t)"
      ],
      "metadata": {
        "id": "ppJMFLLowmsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_of_words = netflix.Clean_Text\n",
        ""
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "t_vectorizer = TfidfVectorizer(max_features=20000)\n",
        "X= t_vectorizer.fit_transform(bag_of_words)"
      ],
      "metadata": {
        "id": "sf_DsujcwL9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)"
      ],
      "metadata": {
        "id": "2pR0WaSXwdID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "rIeAO5HIwg_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new feature\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Assuming 'netflix' is your DataFrame\n",
        "# ... (Your existing code to load and preprocess the data)\n",
        "\n",
        "# 1. Text Vectorization:\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(netflix['description'])\n",
        "\n",
        "# 2. Cosine Similarity Calculation:\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# 3. Recommendation Function:\n",
        "def get_recommendations(title, cosine_sim=cosine_sim):\n",
        "    # Get the index of the movie that matches the title\n",
        "    idx = netflix[netflix['title'] == title].index[0]\n",
        "\n",
        "    # Get the pairwise similarity scores of all movies with that movie\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "    # Sort the movies based on the similarity scores\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the top 10 most similar movies (excluding the movie itself)\n",
        "    sim_scores = sim_scores[1:11]\n",
        "\n",
        "    # Return the titles of the most similar movies\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    return netflix['title'].iloc[movie_indices]\n",
        "\n",
        "# Example usage:\n",
        "recommendations = get_recommendations('Stranger Things')\n",
        "print(recommendations)"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA to reduce the dimensionality of the dataset. PCA identifies the directions (principal components) along which the data varies the most. These components are ordered by the amount of variance they explain in the data."
      ],
      "metadata": {
        "id": "glLUP4FAwsTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "transformer = PCA()\n",
        "transformer.fit(X.toarray())"
      ],
      "metadata": {
        "id": "crqbQtdCv9kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA can extract the most relevant features from a dataset. It transforms the original features into a new set of uncorrelated variables called principal components. These components are linear combinations of the original features and capture the maximum amount of variation present in the data."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5), dpi=120)\n",
        "plt.plot(np.cumsum(transformer.explained_variance_ratio_))\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance')\n",
        "plt.axhline(y=0.95, color='r', linestyle='--',linewidth=2, label='95% Explained Variance')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rZt0sK4jw-mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot helps in determining the number of components to consider for dimensionality reduction. You can select the number of components where the cumulative explained variance reaches a satisfactory threshold, such as 95%. The point where the curve intersects or is closest to the threshold line can guide you in choosing the appropriate number of components for your analysis."
      ],
      "metadata": {
        "id": "QgFsjGdBy4ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.decomposition import PCA\n",
        "# Create an instance of PCA with the desired explained variance ratio\n",
        "pca_tuned = PCA(n_components=0.95)\n",
        "# Fit the PCA model on the input data, X, which is converted to a dense array\n",
        "pca_tuned.fit(X.toarray())\n",
        "# Transform the input data, X, to its reduced dimensional representation\n",
        "X_transformed = pca_tuned.transform(X.toarray())\n",
        "# Print the shape of the transformed data to see the number of samples and transformed features\n",
        "print(X_transformed.shape)\n"
      ],
      "metadata": {
        "id": "CwPAa845y6At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_transformed"
      ],
      "metadata": {
        "id": "gvbjvplszIBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}